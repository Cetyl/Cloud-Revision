
# Creating a Kubernetes Cluster on AWS EKS (via AWS Console)

This guide walks you through the process of creating a Kubernetes cluster on AWS using **Amazon Elastic Kubernetes Service (EKS)** via the AWS Management Console. This guide includes steps for setting up IAM roles for both the EKS control plane and the worker nodes.

## Prerequisites

Before starting, ensure you meet the following prerequisites:

1. **AWS Account**: You need an active AWS account. If you don’t have one, you can create it at [AWS](https://aws.amazon.com/).
2. **IAM User with Permissions**: Ensure you have an IAM user with the following permissions:
   - `AmazonEKSFullAccess`
   - `AmazonEC2FullAccess`
   - `AmazonS3FullAccess`
   - `IAMFullAccess`

3. **Kubernetes CLI (kubectl)**: While kubectl can be optional for creation via the interface, you will need it later to manage the cluster after creation. 
   - [Install kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/)

---

## Step 1: Sign in to AWS Management Console

1. Go to the [AWS Management Console](https://aws.amazon.com/console/).
2. Sign in with your credentials.

---

## Step 2: Open EKS Service

1. From the AWS Management Console, search for **EKS** in the search bar or navigate to **Services > Compute > Elastic Kubernetes Service**.

---

## Step 3: Create a New Cluster

1. In the EKS Dashboard, click the **Create cluster** button to start creating a new Kubernetes cluster.

---

### Step 3.1: Configure Cluster Settings

1. **Cluster Name**: Enter a unique name for your cluster. For example, `my-k8s-cluster`.
   
2. **Kubernetes Version**: Select the desired Kubernetes version. For a stable setup, it’s recommended to use the latest version (as of this writing, 1.24, 1.25, or 1.26).

3. **Cluster Service Role**: 
   - **Role Creation**: If you don't have a pre-existing IAM role for the EKS control plane, you'll need to create one. This role allows Amazon EKS to interact with other AWS services on your behalf (e.g., EC2, CloudWatch, IAM, etc.).
     - Click **Create new role**.
     - In the dialog that appears, ensure the following policy is attached to the IAM role:
       - **AmazonEKSClusterPolicy**
     - Once the role is created, select it.

4. **VPC Configuration**:
   - EKS will automatically create a VPC with the required subnets, route tables, and security groups for you. You can either select an existing VPC or allow EKS to create a new one for the cluster.
   - If creating a new VPC, EKS will automatically configure subnets, routing, and Internet Gateway for public access.

5. **Networking**: 
   - Choose **Default networking** or configure custom networking if you require more control over subnets, security groups, etc.
   - Ensure that you select both **public and private subnets** for redundancy and fault tolerance.

6. **Cluster Logging**: (Optional)
   - Enable logging to CloudWatch for easier monitoring of the cluster’s health and performance.
   - You can choose to log:
     - **API Server**
     - **Scheduler**
     - **Controller Manager**

---

### Step 3.2: Review and Create the Cluster

1. After reviewing your cluster settings, click **Create**. The creation of the control plane (master node) will begin. This can take 10-15 minutes.

Once the cluster is created, you will be redirected to the cluster dashboard.

---

## Step 4: Create Node Group (Worker Nodes)

After the cluster control plane is provisioned, you need to add worker nodes (EC2 instances) to run your workloads.

1. In the cluster dashboard, click on **Add Node Group** or **Create node group**.

---

### Step 4.1: Configure Node Group Settings

1. **Node Group Name**: Choose a name for the node group, e.g., `my-node-group`.
2. **Node IAM Role**:
   - **Role Creation**: If you don't have a pre-existing IAM role for your worker nodes, you'll need to create one. This IAM role grants the nodes the necessary permissions to interact with other AWS resources.
   - Click **Create new role**.
   - In the dialog that appears, ensure the following policies are attached to the IAM role:
     - **AmazonEKSWorkerNodePolicy**
     - **AmazonEC2ContainerRegistryReadOnly** (if pulling Docker images from Amazon ECR)
     - **AmazonEKS_CNI_Policy** (for VPC networking)
   - Select the role once created.

3. **Node Type**: Choose the EC2 instance type for your worker nodes. For example, `t3.medium` is a good option for a small to medium workload.

4. **Number of Nodes**: Configure the number of worker nodes. You can set the minimum and maximum number of nodes for auto-scaling, but starting with 3 nodes is typical.

5. **Scaling Configuration**: 
   - Set **Minimum** and **Maximum** numbers of nodes in your node group. EKS will automatically scale the number of worker nodes based on resource utilization (e.g., CPU and memory).

---

### Step 4.2: Configure Networking

1. **Subnets**: Choose the subnets where your worker nodes will be launched. You can allow EKS to automatically choose available subnets.
2. **Security Groups**: Select an existing security group for your worker nodes, or create a new security group if necessary. Ensure that the security group allows appropriate inbound and outbound traffic for Kubernetes (e.g., TCP ports 6443 for the API server).

---

### Step 4.3: Review and Create Node Group

1. After reviewing your node group configuration, click **Create**. EKS will begin provisioning the worker nodes.
2. The creation of worker nodes will take a few minutes.

---

## Step 5: Verify Cluster and Nodes

Once the node group is created, your EKS cluster should now have both the control plane (managed by AWS) and the worker nodes (EC2 instances).

To verify that everything is working:

1. In the AWS Console, go to **EKS > Clusters > [Your Cluster] > Nodes**.
2. Verify that the status of the worker nodes is **Active**.

Additionally, you can use `kubectl` to check the status of the nodes:

```bash
kubectl get nodes
```

---

## Step 6: Configure kubectl to Access the Cluster

To interact with your Kubernetes cluster from your local machine, you need to configure your `kubeconfig` file.

1. In the AWS Console, go to **EKS > Clusters**.
2. Select the cluster you created.
3. Click on **Connect** and follow the instructions to update your kubeconfig file.
4. After configuring, verify the connection using the following `kubectl` command:

   ```bash
   kubectl get nodes
   ```

   You should see the worker nodes listed.

---

## Step 7: Deploy an Application to Your EKS Cluster

To deploy a test application to your EKS cluster:

1. **Create a deployment**:

   ```bash
   kubectl create deployment nginx --image=nginx
   ```

2. **Expose the deployment**:

   ```bash
   kubectl expose deployment nginx --port=80 --type=LoadBalancer
   ```

3. **Get the external IP**:

   After a few minutes, check the external IP of your application:

   ```bash
   kubectl get services
   ```

   The `EXTERNAL-IP` field will show the IP address. Open it in your browser to view the Nginx default page.

---

## Step 8: Clean Up Resources

To delete your EKS cluster and all associated resources:

1. In the AWS Console, navigate to **EKS > Clusters**.
2. Select the cluster you want to delete.
3. Click **Delete Cluster**.

EKS will remove the cluster, node group, and associated resources. Be aware that this action cannot be undone.

---

## Conclusion

You have successfully created a Kubernetes cluster on AWS EKS using the AWS Management Console! You can now deploy, scale, and manage applications within your Kubernetes environment.

---

## Useful Links

- [Amazon EKS Documentation](https://docs.aws.amazon.com/eks/latest/userguide/)
- [Create EKS Cluster via AWS Console](https://docs.aws.amazon.com/eks/latest/userguide/create-cluster.html)
- [Amazon EKS Pricing](https://aws.amazon.com/eks/pricing/)

---
### Key Additions:

- **IAM Role for Cluster Service**: When creating the EKS cluster, you need to ensure that the control plane has the necessary IAM permissions by selecting or creating an IAM role with the `AmazonEKSClusterPolicy`.
- **IAM Role for Worker Nodes**: When creating the node group, you'll need to create an IAM role for the worker nodes with the following policies:
  - `AmazonEKSWorkerNodePolicy`
  - `AmazonEC2ContainerRegistryReadOnly`
  - `AmazonEKS_CNI_Policy`

This ensures the worker nodes have the necessary permissions to interact with the EKS control plane and other AWS services, such as Amazon EC2 and ECR.
