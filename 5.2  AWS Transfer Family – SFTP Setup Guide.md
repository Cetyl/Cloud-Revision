# 🚀 AWS Transfer Family – SFTP Setup Guide

## 📘 Overview

This guide explains how to configure a **secure SFTP endpoint** using **AWS Transfer Family** to upload and download files directly to and from **Amazon S3** using **SSH key–based authentication**.

---

## 🏗️ Architecture Diagram

```text
SFTP User
   │
   ▼
AWS Transfer Family (SFTP Endpoint)
   │
   ▼
IAM Role (Access Policy)
   │
   ▼
Amazon S3 Bucket (Data Storage)
```

**Flow Summary:**

1. The SFTP user connects to AWS Transfer Family via SSH key.
2. The server authenticates and assumes an IAM role.
3. The IAM role grants access to a specific S3 bucket.
4. Files are securely transferred between S3 and the user.

---

## 🧰 Prerequisites

* AWS account with admin or equivalent permissions
* Access to AWS Console or CLI
* AWS region (e.g., `ap-south-1`)
* SSH key generation tools (`ssh-keygen` or PuTTYgen)

---

## 🪣 Step 1: Create an S3 Bucket

1. Go to **Amazon S3 → Create bucket**
2. Choose a unique name, e.g., `my-sftp-bucket-demo`
3. Select your preferred AWS Region
4. Enable “Block all public access” for security
5. Click **Create bucket**

✅ *Result:* S3 bucket created to store transferred files.

---

## 🔑 Step 2: Generate SSH Key Pair

### Linux / macOS

```bash
ssh-keygen -t rsa -b 4096 -f sftp-user-key
```

This generates:

* `sftp-user-key` → Private key
* `sftp-user-key.pub` → Public key

Display public key:

```bash
cat sftp-user-key.pub
```

### Windows (PuTTYgen)

1. Open PuTTYgen → Select **RSA** (4096 bits)
2. Click **Generate** and save private key as `sftp-user.ppk`
3. Copy the public key text for AWS configuration

✅ *Result:* SSH keys generated for secure login.

---

## 🧾 Step 3: Create IAM Role for S3 Access

1. Go to **IAM → Roles → Create role**
2. Select **AWS Service** → **Transfer**
3. Attach a **custom policy**:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "ListAndAccessS3Bucket",
      "Effect": "Allow",
      "Action": ["s3:ListBucket"],
      "Resource": "arn:aws:s3:::my-sftp-bucket-demo"
    },
    {
      "Sid": "AllowS3ObjectActions",
      "Effect": "Allow",
      "Action": ["s3:GetObject", "s3:PutObject", "s3:DeleteObject"],
      "Resource": "arn:aws:s3:::my-sftp-bucket-demo/*"
    }
  ]
}
```

4. Name the role **TransferSFTPUserRole** and create it.

✅ *Result:* IAM role created for S3 access.

---

## 🌐 Step 4: Create AWS Transfer Family Server

1. Navigate to **AWS Transfer Family → Create server**
2. Choose:

   * **Protocol:** SFTP
   * **Identity Provider:** Service managed
   * **Logging:** CloudWatch (optional)
3. Click **Create server**

The server will be in a **Stopped** state initially.
Note down the **Server ID** (e.g., `s-1234567890abcdef`).

✅ *Result:* SFTP server created.

---

## 👤 Step 5: Add a User to the Server

1. Open **Transfer Family → Servers → [Your Server] → Users → Add user**
2. Enter:

   * **Username:** `sftpuser1`
   * **IAM Role:** `TransferSFTPUserRole`
   * **Home Directory:** `arn:aws:s3:::my-sftp-bucket-demo/home/sftpuser1/`
   * **SSH Public Key:** Paste from `sftp-user-key.pub`
3. Click **Add user**

✅ *Result:* SFTP user created with SSH key authentication.

---

## ▶️ Step 6: Start the Server

1. From **AWS Transfer Family → Servers → [Your Server]**
2. Click **Start server**
3. Copy the **endpoint**:

   ```
   s-1234567890abcdef.server.transfer.ap-south-1.amazonaws.com
   ```

✅ *Result:* Server is active and ready for connections.

---

## 🧪 Step 7: Test the Connection

### Using CLI

```bash
sftp -i sftp-user-key sftpuser1@s-1234567890abcdef.server.transfer.ap-south-1.amazonaws.com
```

### Using WinSCP

* **Protocol:** SFTP
* **Host:** `s-1234567890abcdef.server.transfer.ap-south-1.amazonaws.com`
* **Username:** `sftpuser1`
* **Private Key:** `sftp-user.ppk`

✅ *Result:* Successful SFTP login and access to the S3 bucket.

---

## ⚙️ Optional Enhancements

* **VPC Access:** Host the SFTP endpoint inside a VPC for private connectivity.
* **Custom Domain:** Map endpoint using Route 53 (e.g., `sftp.mydomain.com`).
* **CloudWatch Logs:** Enable for connection tracking and auditing.
* **Automation:** Use AWS Lambda to process uploaded files automatically.

---

## 🔐 Security Best Practices

* Use SSH keys (not passwords).
* Apply **least privilege** to IAM roles.
* Restrict bucket access by prefix or user.
* Rotate keys periodically.
* Enable **CloudTrail** for full auditing.

---

## 🧩 Troubleshooting

| Issue              | Possible Cause                    | Solution                 |
| ------------------ | --------------------------------- | ------------------------ |
| AccessDenied       | IAM role lacks `s3:PutObject`     | Update IAM policy        |
| Connection timeout | Server stopped / firewall blocked | Start server / check VPC |
| Permission denied  | Wrong username or SSH key         | Verify credentials       |

---

## 📚 References

* [AWS Transfer Family Docs](https://docs.aws.amazon.com/transfer/latest/userguide/what-is-aws-transfer-family.html)
* [Amazon S3 Guide](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html)
* [IAM Policy Reference](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html)

---

## ✅ Conclusion

You now have a **fully managed SFTP solution** using AWS Transfer Family integrated with S3.
This provides:

* Secure SSH-based access
* IAM-based authorization
* Minimal maintenance and high availability

---

**Author:** *[Your Name or Team]*
**Last Updated:** *[Date]*
